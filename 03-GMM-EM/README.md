# 第二次作业 #
## 数据： ##
本次实验所用的数据为0-9（其中0的标签为Z（Zero））和o这11个字符的英文录音，每个录音的原始录音文件和39维的MFCC特征都已经提供，
实验中，每个字符用一个GMM来建模，在测试阶段，对于某句话，对数似然最大的模型对应的字符为当前语音数据的预测的标签（target）

    训练数据：330句话，每个字符30句话，11个字符

    测试数据：110句话，每个字符10句话，11个字符

digit_test/digit_train里面包含了测试和训练用数据，包括：

1) wav.scp, 句子id到wav的路径的映射，所用到的数据wav文件的相对路径

2) feats.scp, 语音识别工具kaldi提取的特征文件之一，句子id到特征数据真实路径和位置的映射

3) feats.ark, 语音识别工具kaldi提取的特征文件之一，特征实际存储在ark文件中，二进制

4) text, 句子id到标签的映射，本实验中标签（语音对应的文本）只能是0-9，o这11个字符

## 程序： ##
kaldi_io.py提供了读取kaldi特征的功能

utils.py 提供了一个特征读取工具

gmm_estimatior.py 核心代码，提供了GMM训练和测试的代码，需要自己完成GMM类中em_estimator 和calc_log_likelihood函数

## 输出： ##
程序最终输出一个acc.txt文件，里面记录了识别准确率
